# -*- coding: utf-8 -*-
"""Data Collection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p4vEl30TnY0rbhB27Mzy5_onH3ZGizD1
"""

import pandas as pd
import numpy as np
pd.set_option('display.max.columns',None)

links = pd.read_csv('/content/drive/MyDrive/Dataset/tmdb-movie-dataset/links.csv')
ratings = pd.read_csv('/content/drive/MyDrive/Dataset/tmdb-movie-dataset/ratings.csv')
metadata = pd.read_csv('/content/drive/MyDrive/Dataset/tmdb-movie-dataset/movies_metadata.csv')
keywords = pd.read_csv('/content/drive/MyDrive/Dataset/tmdb-movie-dataset/keywords.csv')
credits = pd.read_csv('/content/drive/MyDrive/Dataset/tmdb-movie-dataset/credits.csv')
tags = pd.read_csv('/content/drive/MyDrive/Dataset/tmdb-movie-dataset/tags.csv')

"""##dropping movieId which missing tbdbId from links, ratings, tags"""

links.shape, links.head()

dl_movieid = list(links[np.isnan(links['tmdbId'])]['movieId'].values)
dl_movieid.append(6003)
dl_movieid.append(144606)
dl_movieid

links.isnull().sum(), links.shape

ratings.isnull().sum(), ratings.shape

tags.head()

tags.isnull().sum()

links = links[~links['movieId'].isin(dl_movieid)]
links['tmdbId'] = links['tmdbId'].astype('int')
ratings = ratings[~ratings['movieId'].isin(dl_movieid)]
tags = tags[~tags['movieId'].isin(dl_movieid)]

"""##Modifying metadata"""

metadata.isnull().sum()

metadata.dropna(subset=['vote_count'], inplace=True)
metadata.drop(columns=['adult','belongs_to_collection', 'budget', 'homepage', 'imdb_id', 'original_language',
                       'original_title', 'poster_path', 'production_companies', 'production_countries', 'revenue',
                       'runtime', 'spoken_languages', 'status', 'video', 'vote_count'], inplace=True)
metadata.dropna(subset=['release_date', 'overview'], inplace=True)
metadata.drop_duplicates(subset=['id'], keep='last', inplace=True)
metadata['id'] = metadata['id'].astype('int')
metadata['release_date'] = metadata['release_date'].apply(lambda x : int(x[0:4]))
metadata = metadata[metadata['release_date']>1960].reset_index(drop=True) # removing very old movies
metadata['tagline'] = metadata[['tagline']].fillna("")

df = pd.merge(links, metadata, how='inner', left_on='tmdbId', right_on='id')
metadata_col = metadata.columns
metadata = df.loc[:,metadata_col]

metadata.shape, df.shape

unavailable_data_movieid = links[~links['tmdbId'].isin(metadata['id'])]['movieId'].values

metadata.to_csv('/content/drive/MyDrive/Dataset/data/movies_metadata_small.csv',index=False)

"""##Modifying Keywords"""

keywords.head()

keywords.shape

keywords.isnull().sum()

keywords.drop_duplicates(subset=['id'], keep='last', inplace=True)
df1 = pd.merge(df, keywords, how='inner', on='id')
keywords_col = keywords.columns
keywords = df1[keywords_col]
keywords.shape, df1.shape

keywords.to_csv('/content/drive/MyDrive/Dataset/data/keywords_small.csv',index=False)

"""##Modifying Credit"""

credits.head()

credits.isnull().sum()

credits.drop_duplicates(subset=['id'], keep='last', inplace=True)
df2 = pd.merge(df, credits, how='inner', on='id')
credits_col = credits.columns
credits = df2[credits_col]
credits.shape, df2.shape

credits.to_csv('/content/drive/MyDrive/Dataset/data/credits_small.csv',index=False)

"""##Removing movieId whose corresponding data in TMDB data is not available from links, ratings, tags"""

links.shape, ratings.shape, tags.shape

links = links[~(links['movieId'].isin(unavailable_data_movieid))]
ratings = ratings[~(ratings['movieId'].isin(unavailable_data_movieid))]
tags = tags[~(tags['movieId'].isin(unavailable_data_movieid))]
links.shape, ratings.shape, tags.shape

links.to_csv('/content/drive/MyDrive/Dataset/data/links_small.csv',index=False)
ratings.to_csv('/content/drive/MyDrive/Dataset/data/ratings_small.csv',index=False)
tags.to_csv('/content/drive/MyDrive/Dataset/data/tags_small.csv',index=False)